{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e6a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from all stations...\n",
      "Collected yearly data for progressive_trend_tables_AT-Neu - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_AT-Neu - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_BE-Bra - Period: 4\n",
      "Collected JJA data for progressive_trend_tables_BE-Bra - Period: 8\n",
      "Collected yearly data for progressive_trend_tables_BE-Lon - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_BE-Lon - Period: 7\n",
      "Collected yearly data for progressive_trend_tables_BE-Vie - Period: 3\n",
      "Collected JJA data for progressive_trend_tables_BE-Vie - Period: 6\n",
      "Collected yearly data for progressive_trend_tables_CH-Cha - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_CH-Cha - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_CH-Dav - Period: 5\n",
      "Collected JJA data for progressive_trend_tables_CH-Dav - Period: 4\n",
      "Collected yearly data for progressive_trend_tables_CH-Fru - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_CH-Fru - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_CZ-BK1 - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_CZ-BK1 - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_CZ-wet - Period: 3\n",
      "Collected JJA data for progressive_trend_tables_CZ-wet - Period: 4\n",
      "Collected yearly data for progressive_trend_tables_DE-Geb - Period: 3\n",
      "Collected JJA data for progressive_trend_tables_DE-Geb - Period: 4\n",
      "Collected yearly data for progressive_trend_tables_DE-Gri - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_DE-Gri - Period: 3\n",
      "Collected yearly data for progressive_trend_tables_DE-Hai - Period: 4\n",
      "Collected JJA data for progressive_trend_tables_DE-Hai - Period: 5\n",
      "Collected yearly data for progressive_trend_tables_DE-HoH - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_DE-HoH - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_DE-Hzd - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_DE-Hzd - Period: 3\n",
      "Collected yearly data for progressive_trend_tables_DE-Kli - Period: 2\n",
      "Collected JJA data for progressive_trend_tables_DE-Kli - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_DE-Lnf - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_DE-Obe - Period: 2\n",
      "Collected JJA data for progressive_trend_tables_DE-Obe - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_DE-RuR - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_DE-RuR - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_DE-RuS - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_DE-RuS - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_DE-Tha - Period: 6\n",
      "Collected JJA data for progressive_trend_tables_DE-Tha - Period: 6\n",
      "Collected yearly data for progressive_trend_tables_DK-Sor - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_DK-Sor - Period: 3\n",
      "Collected yearly data for progressive_trend_tables_ES-Agu - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_ES-Agu - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_ES-LJu - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_ES-LJu - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_FI-Hyy - Period: 3\n",
      "Collected JJA data for progressive_trend_tables_FI-Hyy - Period: 4\n",
      "Collected yearly data for progressive_trend_tables_FI-Let - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_FI-Let - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_FI-Sod - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_FI-Sod - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_FR-Aur - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_FR-Aur - Period: 2\n",
      "Collected yearly data for progressive_trend_tables_FR-Bil - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_FR-Bil - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_FR-Gri - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_FR-Gri - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_FR-Hes - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_FR-Lam - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_FR-Lam - Period: 3\n",
      "Collected yearly data for progressive_trend_tables_FR-LBr - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_FR-LBr - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_IT-BCi - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-BCi - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_IT-Col - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-Col - Period: 2\n",
      "Collected JJA data for progressive_trend_tables_IT-Cp2 - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_IT-Cpz - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-Cpz - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_IT-Lav - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-Lav - Period: 3\n",
      "Collected yearly data for progressive_trend_tables_IT-MBo - Period: 4\n",
      "Collected JJA data for progressive_trend_tables_IT-MBo - Period: 8\n",
      "Collected yearly data for progressive_trend_tables_IT-Ren - Period: 2\n",
      "Collected JJA data for progressive_trend_tables_IT-Ren - Period: 6\n",
      "Collected yearly data for progressive_trend_tables_IT-Ro2 - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-Ro2 - Period: 1\n",
      "Collected JJA data for progressive_trend_tables_IT-SR2 - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_IT-SRo - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-SRo - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_IT-Tor - Period: 4\n",
      "Collected JJA data for progressive_trend_tables_IT-Tor - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_IT-TrF - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_IT-TrF - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_NL-Loo - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_NL-Loo - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_RU-Fyo - Period: 2\n",
      "Collected JJA data for progressive_trend_tables_RU-Fyo - Period: 5\n",
      "Collected yearly data for progressive_trend_tables_SE-Deg - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_SE-Deg - Period: 1\n",
      "Collected yearly data for progressive_trend_tables_SE-Htm - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_SE-Htm - Period: 0\n",
      "Collected yearly data for progressive_trend_tables_SE-Nor - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_SE-Nor - Period: 0\n",
      "Collected JJA data for progressive_trend_tables_SE-Svb - Period: 0\n",
      "Data collection complete. Total records: 586\n",
      "Creating comprehensive analysis plots...\n",
      "Comprehensive selection file saved: C:\\Deepak\\stations\\MM\\Final1\\yearly\\commonstats_output_final\\comprehensive_selected_periods_analysis.xlsx\n",
      "Comprehensive bar plot created for Yearly season\n",
      "Comprehensive bar plot created for JJA (Summer) season\n",
      "Comprehensive bar plots created for both seasons!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\matplotlib_venn\\layout\\venn3\\pairwise.py:169: UserWarning: Bad circle positioning.\n",
      "  warnings.warn(\"Bad circle positioning.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Venn diagrams created for Yearly season (2x3 layout)\n",
      "Combined Venn diagrams created for JJA season (2x3 layout)\n",
      "Venn diagrams created for both seasons!\n",
      "All comprehensive analysis completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import seaborn as sns\n",
    "\n",
    "# Define parameters\n",
    "parameters = [\n",
    "    'LE_CORR', 'H_CORR', 'TA_F', 'VPD_F', 'P_F', 'H_F_MDS', \n",
    "    'GPP_DT_VUT_MEAN', 'LE_F_MDS', 'G_F_MDS', 'TS_F_MDS_1', \n",
    "    'NETRAD', 'SWC_F_MDS_1'\n",
    "]\n",
    "\n",
    "# Directory containing Excel files\n",
    "input_directory = r'C:\\Deepak\\stations\\MM\\Final1\\yearly'\n",
    "output_directory = r'C:\\Deepak\\stations\\MM\\Final1\\yearly\\commonstats_output_final'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Global storage for significance data across all stations (only selected periods)\n",
    "all_stations_selected_data = []\n",
    "\n",
    "# Get list of Excel files - separate yearly and JJA files\n",
    "yearly_files = [f for f in os.listdir(input_directory) if f.endswith('_yearly.xlsx')]\n",
    "jja_files = [f for f in os.listdir(input_directory) if f.endswith('_JJA.xlsx')]\n",
    "\n",
    "# Create a mapping between yearly and JJA files\n",
    "file_pairs = {}\n",
    "for y_file in yearly_files:\n",
    "    base_name = y_file.replace('_yearly.xlsx', '')\n",
    "    jja_file = base_name + '_JJA.xlsx'\n",
    "    if jja_file in jja_files:\n",
    "        file_pairs[base_name] = {'yearly': y_file, 'jja': jja_file}\n",
    "    else:\n",
    "        file_pairs[base_name] = {'yearly': y_file, 'jja': None}\n",
    "\n",
    "# Also include JJA files that don't have yearly counterparts\n",
    "for j_file in jja_files:\n",
    "    base_name = j_file.replace('_JJA.xlsx', '')\n",
    "    if base_name not in file_pairs:\n",
    "        file_pairs[base_name] = {'yearly': None, 'jja': j_file}\n",
    "\n",
    "def calculate_score_and_selection(p_values_df, slopes_df, parameters):\n",
    "    \"\"\"Calculate scores and determine selected periods based on highest scores\"\"\"\n",
    "    scores_by_period = {}\n",
    "    \n",
    "    for period_idx in range(len(p_values_df)):\n",
    "        period_score = 0\n",
    "        sig_count = 0\n",
    "        \n",
    "        for param in parameters:\n",
    "            if param not in p_values_df.columns or param not in slopes_df.columns:\n",
    "                continue\n",
    "                \n",
    "            p_val = p_values_df[param].iloc[period_idx]\n",
    "            slope = slopes_df[param].iloc[period_idx]\n",
    "            \n",
    "            if pd.isna(p_val) or pd.isna(slope):\n",
    "                continue\n",
    "            \n",
    "            # Calculate score based on significance\n",
    "            if p_val < 0.1:\n",
    "                period_score += 0.9\n",
    "                sig_count += 1\n",
    "            elif p_val < 0.2:\n",
    "                period_score += 0.5\n",
    "                sig_count += 1\n",
    "            else:\n",
    "                period_score += 0.1\n",
    "        \n",
    "        scores_by_period[period_idx] = {\n",
    "            'score': period_score,\n",
    "            'sig_count': sig_count,\n",
    "            'period_name': slopes_df['Years'].iloc[period_idx] if 'Years' in slopes_df.columns else f'Period_{period_idx}'\n",
    "        }\n",
    "    \n",
    "    # Select period with highest score (tie-breaker: most significant counts)\n",
    "    if scores_by_period:\n",
    "        selected_period = max(scores_by_period.keys(), \n",
    "                            key=lambda x: (scores_by_period[x]['score'], \n",
    "                                         scores_by_period[x]['sig_count']))\n",
    "        return scores_by_period, selected_period\n",
    "    return {}, None\n",
    "\n",
    "def get_selected_period_data(station_name, p_values_df, slopes_df, parameters, selected_period_idx, season):\n",
    "    \"\"\"Get data for the selected period only\"\"\"\n",
    "    selected_data = []\n",
    "    \n",
    "    for param in parameters:\n",
    "        if param not in p_values_df.columns or param not in slopes_df.columns:\n",
    "            continue\n",
    "            \n",
    "        p_val = p_values_df[param].iloc[selected_period_idx]\n",
    "        slope = slopes_df[param].iloc[selected_period_idx]\n",
    "        \n",
    "        if pd.isna(p_val) or pd.isna(slope):\n",
    "            continue\n",
    "        \n",
    "        # Determine significance level\n",
    "        if p_val < 0.1:\n",
    "            sig_level = 'high'\n",
    "            score_contribution = 0.9\n",
    "        elif p_val < 0.2:\n",
    "            sig_level = 'medium'\n",
    "            score_contribution = 0.5\n",
    "        else:\n",
    "            sig_level = 'insig'\n",
    "            score_contribution = 0.1\n",
    "        \n",
    "        selected_data.append({\n",
    "            'station': station_name,\n",
    "            'parameter': param,\n",
    "            'season': season,\n",
    "            'significance': sig_level,\n",
    "            'p_value': p_val,\n",
    "            'slope': slope,\n",
    "            'score_contribution': score_contribution,\n",
    "            'period': p_values_df['Years'].iloc[selected_period_idx] if 'Years' in p_values_df.columns else f'Period_{selected_period_idx}'\n",
    "        })\n",
    "    \n",
    "    return selected_data\n",
    "\n",
    "def create_comprehensive_bar_plots_separate_seasons():\n",
    "    \"\"\"Create separate comprehensive bar plots for Yearly and JJA seasons\"\"\"\n",
    "    \n",
    "    # Filter data by season\n",
    "    yearly_data = [record for record in all_stations_selected_data if record['season'] == 'yearly']\n",
    "    jja_data = [record for record in all_stations_selected_data if record['season'] == 'JJA']\n",
    "    \n",
    "    # Create separate plots for yearly and JJA\n",
    "    for season, season_data, season_name in [('yearly', yearly_data, 'Yearly'), ('JJA', jja_data, 'JJA (Summer)')]:\n",
    "        if len(season_data) == 0:\n",
    "            print(f\"No data available for {season_name}\")\n",
    "            continue\n",
    "            \n",
    "        # Create summary data for bar plot\n",
    "        param_summary = {}\n",
    "        for param in parameters:\n",
    "            param_summary[param] = {'high_sig': 0, 'medium_sig': 0, 'insig_sig': 0}\n",
    "        \n",
    "        for record in season_data:\n",
    "            param = record['parameter']\n",
    "            sig_level = record['significance']\n",
    "            \n",
    "            # Map significance level to correct key\n",
    "            if sig_level == 'high':\n",
    "                key = 'high_sig'\n",
    "            elif sig_level == 'medium':\n",
    "                key = 'medium_sig'\n",
    "            else:  # insig\n",
    "                key = 'insig_sig'\n",
    "            \n",
    "            param_summary[param][key] += 1\n",
    "        \n",
    "        # Prepare data for stacked bar plot - REVERSED ORDER\n",
    "        params = list(param_summary.keys())\n",
    "        insig = [param_summary[param]['insig_sig'] for param in params]  # Bottom layer\n",
    "        medium_sig = [param_summary[param]['medium_sig'] for param in params]  # Middle layer\n",
    "        high_sig = [param_summary[param]['high_sig'] for param in params]  # Top layer\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = plt.subplots(figsize=(16, 10))\n",
    "        \n",
    "        bar_width = 0.8\n",
    "        x_pos = np.arange(len(params))\n",
    "        \n",
    "        # Plot in reversed order: Not significant at bottom, then medium, then high\n",
    "        bars1 = ax.bar(x_pos, insig, bar_width, label='Not Significant (p ≥ 0.2)', \n",
    "                       color='#d62728', edgecolor='black', linewidth=1)\n",
    "        bars2 = ax.bar(x_pos, medium_sig, bar_width, bottom=insig, \n",
    "                       label='Moderately Significant (0.1 ≤ p < 0.2)', \n",
    "                       color='#ff7f0e', edgecolor='black', linewidth=1)\n",
    "        bars3 = ax.bar(x_pos, high_sig, bar_width, bottom=np.array(insig) + np.array(medium_sig),\n",
    "                       label='Highly Significant (p < 0.1)', \n",
    "                       color='#2ca02c', edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (n, m, h) in enumerate(zip(insig, medium_sig, high_sig)):\n",
    "            total = n + m + h\n",
    "            if total > 0:\n",
    "                # Total count at top of bar\n",
    "                ax.text(i, total + 0.1, f'{total}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "                \n",
    "                # Percentage labels for each segment\n",
    "                if n > 0:  # Not significant\n",
    "                    ax.text(i, n/2, f'{n}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "                \n",
    "                if m > 0:  # Moderately significant\n",
    "                    ax.text(i, n + m/2, f'{m}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "                \n",
    "                if h > 0:  # Highly significant\n",
    "                    ax.text(i, n + m + h/2, f'{h}', ha='center', va='center', \n",
    "                           fontweight='bold', fontsize=9, color='white')\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Parameters', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Number of Stations', fontsize=14, fontweight='bold')\n",
    "        ax.set_title(f'Significance Analysis - {season_name} Season', \n",
    "                     fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "        \n",
    "        # Calculate statistics for annotation\n",
    "        total_stations = len(set([record['station'] for record in season_data]))\n",
    "        total_high = sum(high_sig)\n",
    "        total_medium = sum(medium_sig)\n",
    "        total_insig = sum(insig)\n",
    "        total_all = total_high + total_medium + total_insig\n",
    "        sig_percentage = (total_high + total_medium) / total_all * 100 if total_all > 0 else 0\n",
    "        \n",
    "        # Add statistics outside the plot area\n",
    "        stats_text = (\n",
    "            f'Total Stations: {total_stations}\\n'\n",
    "            f'Total Parameters: {total_all}\\n'\n",
    "            f' Significant : {total_high} ({total_high/total_all*100:.1f}%)\\n'\n",
    "            f'Moderately Significant: {total_medium} ({total_medium/total_all*100:.1f}%)\\n'\n",
    "            f'Not Significant: {total_insig} ({total_insig/total_all*100:.1f}%)\\n'\n",
    "            f'Overall Significant: {total_high + total_medium}/{total_all} ({sig_percentage:.1f}%)'\n",
    "        )\n",
    "        \n",
    "        # Place statistics on the right side outside the plot\n",
    "        ax.text(1.02, 0.5, stats_text, transform=ax.transAxes, fontsize=11, \n",
    "                fontweight='bold', verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                linespacing=1.5)\n",
    "        \n",
    "        # Adjust plot margins to accommodate the statistics text\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_directory, f'comprehensive_significance_{season}.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Comprehensive bar plot created for {season_name} season\")\n",
    "\n",
    "def create_combined_venn_diagrams_2x3():\n",
    "    \"\"\"Create combined Venn diagrams in 2x3 grid with 6 specific combinations\"\"\"\n",
    "    \n",
    "    if len(all_stations_selected_data) == 0:\n",
    "        print(\"No selected period data found for Venn diagrams\")\n",
    "        return\n",
    "    \n",
    "    # Create a figure with 2 rows and 3 columns\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    \n",
    "    # Process data for both seasons\n",
    "    yearly_data = [record for record in all_stations_selected_data if record['season'] == 'yearly']\n",
    "    jja_data = [record for record in all_stations_selected_data if record['season'] == 'JJA']\n",
    "    \n",
    "    # Create sets for both seasons\n",
    "    season_sets = {}\n",
    "    \n",
    "    for season, season_data in [('yearly', yearly_data), ('JJA', jja_data)]:\n",
    "        sig_season_data = [record for record in season_data if record['p_value'] < 0.2]\n",
    "        \n",
    "        if len(sig_season_data) == 0:\n",
    "            print(f\"No significant records found for {season} season\")\n",
    "            season_sets[season] = {}\n",
    "            continue\n",
    "        \n",
    "        # Create DataFrame for easier manipulation\n",
    "        sig_df = pd.DataFrame(sig_season_data)\n",
    "        \n",
    "        # Group by station and parameter\n",
    "        station_params = sig_df.groupby(['station', 'parameter']).size().reset_index()\n",
    "        \n",
    "        # Create sets for all parameters\n",
    "        sets = {}\n",
    "        for param in parameters:\n",
    "            param_set = set(station_params[station_params['parameter'] == param]['station'])\n",
    "            sets[param] = param_set\n",
    "        \n",
    "        # Also create sets for specific parameter combinations\n",
    "        le_mds_stations = set(station_params[station_params['parameter'] == 'LE_F_MDS']['station'])\n",
    "        h_mds_stations = set(station_params[station_params['parameter'] == 'H_F_MDS']['station'])\n",
    "        netrad_stations = set(station_params[station_params['parameter'] == 'NETRAD']['station'])\n",
    "        le_corr_stations = set(station_params[station_params['parameter'] == 'LE_CORR']['station'])\n",
    "        h_corr_stations = set(station_params[station_params['parameter'] == 'H_CORR']['station'])\n",
    "        gpp_stations = set(station_params[station_params['parameter'] == 'GPP_DT_VUT_MEAN']['station'])\n",
    "        ta_stations = set(station_params[station_params['parameter'] == 'TA_F']['station'])\n",
    "        vpd_stations = set(station_params[station_params['parameter'] == 'VPD_F']['station'])\n",
    "        swc_stations = set(station_params[station_params['parameter'] == 'SWC_F_MDS_1']['station'])\n",
    "        ts_stations = set(station_params[station_params['parameter'] == 'TS_F_MDS_1']['station'])\n",
    "        gf_stations = set(station_params[station_params['parameter'] == 'G_F_MDS']['station'])\n",
    "        p_stations = set(station_params[station_params['parameter'] == 'P_F']['station'])\n",
    "        \n",
    "        season_sets[season] = {\n",
    "            'le_mds': le_mds_stations,\n",
    "            'h_mds': h_mds_stations,\n",
    "            'netrad': netrad_stations,\n",
    "            'le_corr': le_corr_stations,\n",
    "            'h_corr': h_corr_stations,\n",
    "            'gpp': gpp_stations,\n",
    "            'ta': ta_stations,\n",
    "            'vpd': vpd_stations,\n",
    "            'swc': swc_stations,\n",
    "            'ts': ts_stations,\n",
    "            'gf': gf_stations,\n",
    "            'p': p_stations\n",
    "        }\n",
    "    \n",
    "    # Create the 2x3 grid of Venn diagrams\n",
    "    # ROW 1\n",
    "    # 1. LE_CORR, H_CORR, SWC_F_MDS_1 (Top-left)\n",
    "    ax1 = axes[0, 0]\n",
    "    le_mds_yearly = season_sets['yearly'].get('le_mds', set())\n",
    "    h_mds_yearly = season_sets['yearly'].get('h_mds', set())\n",
    "    swc_yearly = season_sets['yearly'].get('swc', set())\n",
    "    le_mds_jja = season_sets['JJA'].get('le_mds', set())\n",
    "    h_mds_jja = season_sets['JJA'].get('h_mds', set())\n",
    "    swc_jja = season_sets['JJA'].get('swc', set())\n",
    "    \n",
    "    # For Yearly season\n",
    "    if le_mds_yearly or h_mds_yearly or swc_yearly:\n",
    "        venn3([le_mds_yearly, h_mds_yearly, swc_yearly],\n",
    "              ['LE_MDS', 'H_MDS', 'SWC'], ax=ax1)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax1.transAxes, fontsize=12)\n",
    "    ax1.set_title('1. LE_MDS vs H_MDS vs SWC\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. LE_MDS vs TA_F vs VPD_F (Top-middle) - Your combination 3\n",
    "    ax2 = axes[0, 1]\n",
    "    le_mds_yearly = season_sets['yearly'].get('le_mds', set())\n",
    "    ta_yearly = season_sets['yearly'].get('ta', set())\n",
    "    vpd_yearly = season_sets['yearly'].get('vpd', set())\n",
    "    \n",
    "    if le_mds_yearly or ta_yearly or vpd_yearly:\n",
    "        venn3([le_mds_yearly, ta_yearly, vpd_yearly],\n",
    "              ['LE_MDS', 'TA_F', 'VPD_F'], ax=ax2)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title('2. LE_MDS vs TA_F vs VPD_F\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. H_F_MDS vs TA_F vs TS_F_MDS (Top-right) - Your combination 5\n",
    "    ax3 = axes[0, 2]\n",
    "    h_mds_yearly = season_sets['yearly'].get('h_mds', set())\n",
    "    ts_yearly = season_sets['yearly'].get('ts', set())\n",
    "    \n",
    "    if h_mds_yearly or ta_yearly or ts_yearly:\n",
    "        venn3([h_mds_yearly, ta_yearly, ts_yearly],\n",
    "              ['H_MDS', 'TA_F', 'TS_MDS'], ax=ax3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('3. H_MDS vs TA_F vs TS_MDS\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # ROW 2\n",
    "    # 4. SWC_F_MDS vs P_F vs H_F_MDS (Bottom-left) - Your combination 4\n",
    "    ax4 = axes[1, 0]\n",
    "    netrad_yearly = season_sets['yearly'].get('netrad', set())\n",
    "    \n",
    "    if le_mds_yearly or  h_mds_yearly or netrad_yearly:\n",
    "        venn3([le_mds_yearly, h_mds_yearly, netrad_yearly],\n",
    "              ['LE_MDS', 'NETRAD', 'H_MDS'], ax=ax4)\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('4. LE_MDS vs H_MDS vs NETRAD\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. H_F_MDS vs G_F_MDS vs SWC_F_MDS (Bottom-middle) - Your combination 6\n",
    "    ax5 = axes[1, 1]\n",
    "    gf_yearly = season_sets['yearly'].get('gf', set())\n",
    "    \n",
    "    if h_mds_yearly or gf_yearly or swc_yearly:\n",
    "        venn3([h_mds_yearly, gf_yearly, swc_yearly],\n",
    "              ['H_MDS', 'G_MDS', 'SWC_MDS'], ax=ax5)\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax5.transAxes, fontsize=12)\n",
    "    ax5.set_title('5. H_MDS vs G_MDS vs SWC_MDS\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. LE_MDS vs H_MDS vs GPP (Bottom-right) - Your combination 7\n",
    "    ax6 = axes[1, 2]\n",
    "    gpp_yearly = season_sets['yearly'].get('gpp', set())\n",
    "    \n",
    "    if le_mds_yearly or h_mds_yearly or gpp_yearly:\n",
    "        venn3([le_mds_yearly, h_mds_yearly, gpp_yearly],\n",
    "              ['LE_MDS', 'H_MDS', 'GPP'], ax=ax6)\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax6.transAxes, fontsize=12)\n",
    "    ax6.set_title('6. LE_MDS vs H_MDS vs GPP\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add overall title\n",
    "    plt.suptitle('Combined Venn Diagrams - Yearly Season (p < 0.2)\\n6 Key Parameter Combinations', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(os.path.join(output_directory, 'combined_venn_diagrams_2x3_yearly.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Combined Venn diagrams created for Yearly season (2x3 layout)\")\n",
    "    \n",
    "    # Now create the same for JJA season\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    \n",
    "    # ROW 1 for JJA\n",
    "    # 1. LE_CORR, H_CORR, SWC_F_MDS_1\n",
    "    ax1 = axes[0, 0]\n",
    "    if le_mds_jja or h_mds_jja or swc_jja:\n",
    "        venn3([le_mds_jja, h_mds_jja, swc_jja],\n",
    "              ['LE_MDS', 'H_MDS', 'SWC'], ax=ax1)\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax1.transAxes, fontsize=12)\n",
    "    ax1.set_title('1. LE_MDS vs H_MDS vs SWC\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. LE_MDS vs TA_F vs VPD_F\n",
    "    ax2 = axes[0, 1]\n",
    "    le_mds_jja = season_sets['JJA'].get('le_mds', set())\n",
    "    ta_jja = season_sets['JJA'].get('ta', set())\n",
    "    vpd_jja = season_sets['JJA'].get('vpd', set())\n",
    "    \n",
    "    if le_mds_jja or ta_jja or vpd_jja:\n",
    "        venn3([le_mds_jja, ta_jja, vpd_jja],\n",
    "              ['LE_MDS', 'TA_F', 'VPD_F'], ax=ax2)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title('2. LE_MDS vs TA_F vs VPD_F\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. H_F_MDS vs TA_F vs TS_F_MDS\n",
    "    ax3 = axes[0, 2]\n",
    "    h_mds_jja = season_sets['JJA'].get('h_mds', set())\n",
    "    ts_jja = season_sets['JJA'].get('ts', set())\n",
    "    \n",
    "    if h_mds_jja or ta_jja or ts_jja:\n",
    "        venn3([h_mds_jja, ta_jja, ts_jja],\n",
    "              ['H_MDS', 'TA_F', 'TS_MDS'], ax=ax3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('3. H_MDS vs TA_F vs TS_MDS\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # ROW 2 for JJA\n",
    "    # 4. SWC_F_MDS vs P_F vs H_F_MDS\n",
    "    ax4 = axes[1, 0]\n",
    "    netrad_jja = season_sets['JJA'].get('netrad', set())\n",
    "    \n",
    "    if le_mds_jja or h_mds_jja or netrad_jja:\n",
    "        venn3([le_mds_jja, h_mds_jja, netrad_jja],\n",
    "              ['LE_MDS', 'H_MDS', 'NETRAD'], ax=ax4)\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('4. LE_MDS vs H_MDS vs NETRAD\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. H_F_MDS vs G_F_MDS vs SWC_F_MDS\n",
    "    ax5 = axes[1, 1]\n",
    "    gf_jja = season_sets['JJA'].get('gf', set())\n",
    "    \n",
    "    if h_mds_jja or gf_jja or swc_jja:\n",
    "        venn3([h_mds_jja, gf_jja, swc_jja],\n",
    "              ['H_MDS', 'G_MDS', 'SWC_MDS'], ax=ax5)\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax5.transAxes, fontsize=12)\n",
    "    ax5.set_title('5. H_MDS vs G_MDS vs SWC_MDS\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. LE_MDS vs H_MDS vs GPP\n",
    "    ax6 = axes[1, 2]\n",
    "    gpp_jja = season_sets['JJA'].get('gpp', set())\n",
    "    \n",
    "    if le_mds_jja or h_mds_jja or gpp_jja:\n",
    "        venn3([le_mds_jja, h_mds_jja, gpp_jja],\n",
    "              ['LE_MDS', 'H_MDS', 'GPP'], ax=ax6)\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'No significant data', ha='center', va='center', \n",
    "                transform=ax6.transAxes, fontsize=12)\n",
    "    ax6.set_title('6. LE_MDS vs H_MDS vs GPP\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add overall title for JJA\n",
    "    plt.suptitle('Combined Venn Diagrams - JJA Summer Season (p < 0.2)\\n6 Key Parameter Combinations', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(os.path.join(output_directory, 'combined_venn_diagrams_2x3_jja.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Combined Venn diagrams created for JJA season (2x3 layout)\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def save_comprehensive_selection_file():\n",
    "    \"\"\"Save comprehensive selection data to Excel file with separate sheets for seasons\"\"\"\n",
    "    if len(all_stations_selected_data) == 0:\n",
    "        print(\"No selected period data to save\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    comp_df = pd.DataFrame(all_stations_selected_data)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_file = os.path.join(output_directory, 'comprehensive_selected_periods_analysis.xlsx')\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        # Save main data\n",
    "        comp_df.to_excel(writer, sheet_name='All_Selected_Periods_Data', index=False)\n",
    "        \n",
    "        # Create separate sheets for yearly and JJA\n",
    "        for season, season_name in [('yearly', 'Yearly'), ('JJA', 'JJA_Summer')]:\n",
    "            season_data = comp_df[comp_df['season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                season_data.to_excel(writer, sheet_name=f'{season_name}_Data', index=False)\n",
    "        \n",
    "        # Create summary sheet\n",
    "        summary_data = []\n",
    "        stations = comp_df['station'].unique()\n",
    "        \n",
    "        for station in stations:\n",
    "            station_data = comp_df[comp_df['station'] == station]\n",
    "            # Separate by season\n",
    "            yearly_data = station_data[station_data['season'] == 'yearly']\n",
    "            jja_data = station_data[station_data['season'] == 'JJA']\n",
    "            \n",
    "            # Yearly summary\n",
    "            if len(yearly_data) > 0:\n",
    "                selected_period_yearly = yearly_data['period'].iloc[0]\n",
    "                high_sig_yearly = len(yearly_data[yearly_data['significance'] == 'high'])\n",
    "                medium_sig_yearly = len(yearly_data[yearly_data['significance'] == 'medium'])\n",
    "                insig_yearly = len(yearly_data[yearly_data['significance'] == 'insig'])\n",
    "                total_params_yearly = len(yearly_data)\n",
    "                total_score_yearly = yearly_data['score_contribution'].sum()\n",
    "            else:\n",
    "                selected_period_yearly = 'N/A'\n",
    "                high_sig_yearly = medium_sig_yearly = insig_yearly = total_params_yearly = total_score_yearly = 0\n",
    "            \n",
    "            # JJA summary\n",
    "            if len(jja_data) > 0:\n",
    "                selected_period_jja = jja_data['period'].iloc[0]\n",
    "                high_sig_jja = len(jja_data[jja_data['significance'] == 'high'])\n",
    "                medium_sig_jja = len(jja_data[jja_data['significance'] == 'medium'])\n",
    "                insig_jja = len(jja_data[jja_data['significance'] == 'insig'])\n",
    "                total_params_jja = len(jja_data)\n",
    "                total_score_jja = jja_data['score_contribution'].sum()\n",
    "            else:\n",
    "                selected_period_jja = 'N/A'\n",
    "                high_sig_jja = medium_sig_jja = insig_jja = total_params_jja = total_score_jja = 0\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Station': station,\n",
    "                'Yearly_Period': selected_period_yearly,\n",
    "                'Yearly_Total_Params': total_params_yearly,\n",
    "                'Yearly_High_Sig': high_sig_yearly,\n",
    "                'Yearly_Medium_Sig': medium_sig_yearly,\n",
    "                'Yearly_Not_Sig': insig_yearly,\n",
    "                'Yearly_Total_Score': total_score_yearly,\n",
    "                'JJA_Period': selected_period_jja,\n",
    "                'JJA_Total_Params': total_params_jja,\n",
    "                'JJA_High_Sig': high_sig_jja,\n",
    "                'JJA_Medium_Sig': medium_sig_jja,\n",
    "                'JJA_Not_Sig': insig_jja,\n",
    "                'JJA_Total_Score': total_score_jja\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Station_Summary', index=False)\n",
    "        \n",
    "        # Create parameter summary sheets for each season\n",
    "        for season, season_name in [('yearly', 'Yearly'), ('JJA', 'JJA')]:\n",
    "            season_data = comp_df[comp_df['season'] == season]\n",
    "            if len(season_data) > 0:\n",
    "                param_summary_data = []\n",
    "                for param in parameters:\n",
    "                    param_data = season_data[season_data['parameter'] == param]\n",
    "                    total_stations = len(param_data)\n",
    "                    high_sig = len(param_data[param_data['significance'] == 'high'])\n",
    "                    medium_sig = len(param_data[param_data['significance'] == 'medium'])\n",
    "                    insig = len(param_data[param_data['significance'] == 'insig'])\n",
    "                    \n",
    "                    param_summary_data.append({\n",
    "                        'Parameter': param,\n",
    "                        'Total_Stations': total_stations,\n",
    "                        'Highly_Significant': high_sig,\n",
    "                        'Moderately_Significant': medium_sig,\n",
    "                        'Not_Significant': insig,\n",
    "                        'Significant_Count': high_sig + medium_sig,\n",
    "                        'Significant_Percentage': ((high_sig + medium_sig) / total_stations * 100) if total_stations > 0 else 0\n",
    "                    })\n",
    "                \n",
    "                param_summary_df = pd.DataFrame(param_summary_data)\n",
    "                param_summary_df.to_excel(writer, sheet_name=f'Parameter_Summary_{season_name}', index=False)\n",
    "    \n",
    "    print(f\"Comprehensive selection file saved: {output_file}\")\n",
    "\n",
    "# Main processing - collect data from all stations\n",
    "print(\"Collecting data from all stations...\")\n",
    "\n",
    "for base_name, files in file_pairs.items():\n",
    "    try:\n",
    "        # Process yearly data\n",
    "        if files['yearly']:\n",
    "            yearly_file_path = os.path.join(input_directory, files['yearly'])\n",
    "            try:\n",
    "                p_values_df_yearly = pd.read_excel(yearly_file_path, sheet_name='P-values')\n",
    "                slopes_df_yearly = pd.read_excel(yearly_file_path, sheet_name='Slopes')\n",
    "                \n",
    "                # Clean the data\n",
    "                p_values_df_yearly = p_values_df_yearly.dropna(how='all')\n",
    "                slopes_df_yearly = slopes_df_yearly.dropna(how='all')\n",
    "                p_values_df_yearly = p_values_df_yearly.reset_index(drop=True)\n",
    "                slopes_df_yearly = slopes_df_yearly.reset_index(drop=True)\n",
    "                \n",
    "                # Calculate scores and selection for yearly data\n",
    "                scores_data_yearly, selected_period_yearly = calculate_score_and_selection(\n",
    "                    p_values_df_yearly, slopes_df_yearly, parameters)\n",
    "                \n",
    "                # Store selected period data for comprehensive analysis\n",
    "                if selected_period_yearly is not None:\n",
    "                    selected_data = get_selected_period_data(\n",
    "                        base_name, p_values_df_yearly, slopes_df_yearly, \n",
    "                        parameters, selected_period_yearly, 'yearly')\n",
    "                    all_stations_selected_data.extend(selected_data)\n",
    "                    print(f\"Collected yearly data for {base_name} - Period: {selected_period_yearly}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading yearly data for {base_name}: {str(e)}\")\n",
    "        \n",
    "        # Process JJA data\n",
    "        if files['jja']:\n",
    "            jja_file_path = os.path.join(input_directory, files['jja'])\n",
    "            try:\n",
    "                p_values_df_jja = pd.read_excel(jja_file_path, sheet_name='P-values')\n",
    "                slopes_df_jja = pd.read_excel(jja_file_path, sheet_name='Slopes')\n",
    "                \n",
    "                # Clean the data\n",
    "                p_values_df_jja = p_values_df_jja.dropna(how='all')\n",
    "                slopes_df_jja = slopes_df_jja.dropna(how='all')\n",
    "                p_values_df_jja = p_values_df_jja.reset_index(drop=True)\n",
    "                slopes_df_jja = slopes_df_jja.reset_index(drop=True)\n",
    "                \n",
    "                # Calculate scores and selection for JJA data\n",
    "                scores_data_jja, selected_period_jja = calculate_score_and_selection(\n",
    "                    p_values_df_jja, slopes_df_jja, parameters)\n",
    "                \n",
    "                # Store selected period data for comprehensive analysis\n",
    "                if selected_period_jja is not None:\n",
    "                    selected_data = get_selected_period_data(\n",
    "                        base_name, p_values_df_jja, slopes_df_jja, \n",
    "                        parameters, selected_period_jja, 'JJA')\n",
    "                    all_stations_selected_data.extend(selected_data)\n",
    "                    print(f\"Collected JJA data for {base_name} - Period: {selected_period_jja}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading JJA data for {base_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_name}: {str(e)}\")\n",
    "\n",
    "print(f\"Data collection complete. Total records: {len(all_stations_selected_data)}\")\n",
    "\n",
    "# Create comprehensive plots and save file\n",
    "print(\"Creating comprehensive analysis plots...\")\n",
    "\n",
    "# Save comprehensive selection file\n",
    "save_comprehensive_selection_file()\n",
    "\n",
    "# Create comprehensive bar plots (separate for yearly and JJA)\n",
    "create_comprehensive_bar_plots_separate_seasons()\n",
    "print(\"Comprehensive bar plots created for both seasons!\")\n",
    "\n",
    "# Create Venn diagrams (separate for yearly and JJA)\n",
    "create_combined_venn_diagrams_2x3()\n",
    "print(\"Venn diagrams created for both seasons!\")\n",
    "\n",
    "print(\"All comprehensive analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd087613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\matplotlib_venn\\layout\\venn3\\pairwise.py:111: UserWarning: Circle C has zero area.\n",
      "  warnings.warn(\"Circle C has zero area.\")\n",
      "c:\\Users\\chinthap\\AppData\\Local\\miniconda3\\envs\\new\\Lib\\site-packages\\matplotlib_venn\\layout\\venn3\\pairwise.py:107: UserWarning: Circle B has zero area.\n",
      "  warnings.warn(\"Circle B has zero area.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yearly Season - Stations with all parameters:\n",
      "  combo1: 3 stations\n",
      "  combo2: 5 stations\n",
      "  combo3: 6 stations\n",
      "  combo4: 4 stations\n",
      "  combo5: 1 stations\n",
      "  combo6: 10 stations\n",
      "\n",
      "JJA Season - Stations with all parameters:\n",
      "  combo1: 14 stations\n",
      "  combo2: 23 stations\n",
      "  combo3: 22 stations\n",
      "  combo4: 22 stations\n",
      "  combo5: 11 stations\n",
      "  combo6: 33 stations\n",
      "\n",
      "Detailed significance data saved to CSV file\n",
      "\n",
      "Venn diagrams created for common stations only\n",
      "Creating all Venn diagram variations...\n"
     ]
    }
   ],
   "source": [
    "def create_combined_venn_diagrams_2x3_common_stations_only():\n",
    "    \"\"\"Create Venn diagrams only for stations that have data for all three parameters in each combination\"\"\"\n",
    "    \n",
    "    if len(all_stations_selected_data) == 0:\n",
    "        print(\"No data found for Venn diagrams\")\n",
    "        return\n",
    "    \n",
    "    # Process data for both seasons\n",
    "    yearly_data = [record for record in all_stations_selected_data if record['season'] == 'yearly']\n",
    "    jja_data = [record for record in all_stations_selected_data if record['season'] == 'JJA']\n",
    "    \n",
    "    # Function to find stations that have data for ALL parameters (irrespective of significance)\n",
    "    def get_stations_with_all_params(season_data, param_names):\n",
    "        \"\"\"Get stations that have data for ALL specified parameters\"\"\"\n",
    "        if not season_data:\n",
    "            return set()\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(season_data)\n",
    "        \n",
    "        # Group by station to see which parameters each station has\n",
    "        station_summary = df.groupby('station')['parameter'].apply(set).reset_index()\n",
    "        \n",
    "        # Find stations that have ALL specified parameters\n",
    "        stations_with_all_params = set()\n",
    "        for _, row in station_summary.iterrows():\n",
    "            station = row['station']\n",
    "            station_params = row['parameter']\n",
    "            \n",
    "            # Check if station has all required parameters\n",
    "            if all(param in station_params for param in param_names):\n",
    "                stations_with_all_params.add(station)\n",
    "        \n",
    "        return stations_with_all_params\n",
    "    \n",
    "    # Function to get significance sets for stations that have all parameters\n",
    "    def get_significance_sets_for_common_stations(season_data, param_names, common_stations):\n",
    "        \"\"\"Get significance sets for stations that have all parameters\"\"\"\n",
    "        if not season_data or not common_stations:\n",
    "            return {param: set() for param in param_names}\n",
    "        \n",
    "        # Filter data for common stations only\n",
    "        common_data = [record for record in season_data if record['station'] in common_stations]\n",
    "        \n",
    "        if not common_data:\n",
    "            return {param: set() for param in param_names}\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(common_data)\n",
    "        \n",
    "        # Get significant stations (p < 0.2) for each parameter\n",
    "        significance_sets = {}\n",
    "        for param in param_names:\n",
    "            # Filter for this parameter and p < 0.2\n",
    "            sig_data = df[(df['parameter'] == param) & (df['p_value'] < 0.2)]\n",
    "            sig_stations = set(sig_data['station'].unique())\n",
    "            significance_sets[param] = sig_stations\n",
    "        \n",
    "        return significance_sets\n",
    "    \n",
    "    # Get parameter combinations\n",
    "    param_combinations = {\n",
    "        'combo1': ['LE_F_MDS', 'H_F_MDS', 'SWC_F_MDS_1'],\n",
    "        'combo2': ['LE_F_MDS', 'TA_F', 'VPD_F'],\n",
    "        'combo3': ['H_F_MDS', 'TA_F', 'TS_F_MDS_1'],\n",
    "        'combo4': ['LE_F_MDS', 'H_F_MDS', 'NETRAD'],\n",
    "        'combo5': ['H_F_MDS', 'G_F_MDS', 'SWC_F_MDS_1'],\n",
    "        'combo6': ['LE_F_MDS', 'H_F_MDS', 'GPP_DT_VUT_MEAN']\n",
    "    }\n",
    "    \n",
    "    # Get common stations and significance sets for both seasons\n",
    "    season_results = {}\n",
    "    \n",
    "    for season_name, season_data in [('yearly', yearly_data), ('JJA', jja_data)]:\n",
    "        season_results[season_name] = {}\n",
    "        \n",
    "        for combo_name, params in param_combinations.items():\n",
    "            # Step 1: Find stations that have data for ALL parameters (irrespective of significance)\n",
    "            common_stations = get_stations_with_all_params(season_data, params)\n",
    "            \n",
    "            # Step 2: Get significance sets for these common stations\n",
    "            if common_stations:\n",
    "                sig_sets = get_significance_sets_for_common_stations(season_data, params, common_stations)\n",
    "            else:\n",
    "                sig_sets = {param: set() for param in params}\n",
    "            \n",
    "            season_results[season_name][combo_name] = {\n",
    "                'common_stations': common_stations,\n",
    "                'significance_sets': sig_sets,\n",
    "                'total_common': len(common_stations)\n",
    "            }\n",
    "    \n",
    "    # Create the 2x3 grid of Venn diagrams for Yearly season\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    \n",
    "    # ROW 1\n",
    "    # 1. LE_MDS, H_MDS, SWC (Top-left)\n",
    "    ax1 = axes[0, 0]\n",
    "    combo1 = season_results['yearly']['combo1']\n",
    "    sig_sets1 = combo1['significance_sets']\n",
    "    \n",
    "    if combo1['total_common'] > 0:\n",
    "        # Get sets for each parameter\n",
    "        le_mds_set = sig_sets1['LE_F_MDS']\n",
    "        h_mds_set = sig_sets1['H_F_MDS']\n",
    "        swc_set = sig_sets1['SWC_F_MDS_1']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, swc_set],\n",
    "              ['LE_MDS', 'H_MDS', 'SWC'], ax=ax1)\n",
    "        \n",
    "        # Add annotation with total common stations\n",
    "        total_common = combo1['total_common']\n",
    "        ax1.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax1.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax1.transAxes, fontsize=12)\n",
    "    ax1.set_title('1. LE_MDS vs H_MDS vs SWC\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. LE_MDS vs TA_F vs VPD_F (Top-middle)\n",
    "    ax2 = axes[0, 1]\n",
    "    combo2 = season_results['yearly']['combo2']\n",
    "    sig_sets2 = combo2['significance_sets']\n",
    "    \n",
    "    if combo2['total_common'] > 0:\n",
    "        le_mds_set = sig_sets2['LE_F_MDS']\n",
    "        ta_set = sig_sets2['TA_F']\n",
    "        vpd_set = sig_sets2['VPD_F']\n",
    "        \n",
    "        venn3([le_mds_set, ta_set, vpd_set],\n",
    "              ['LE_MDS', 'TA_F', 'VPD_F'], ax=ax2)\n",
    "        \n",
    "        total_common = combo2['total_common']\n",
    "        ax2.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax2.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title('2. LE_MDS vs TA_F vs VPD_F\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. H_MDS vs TA_F vs TS_MDS (Top-right)\n",
    "    ax3 = axes[0, 2]\n",
    "    combo3 = season_results['yearly']['combo3']\n",
    "    sig_sets3 = combo3['significance_sets']\n",
    "    \n",
    "    if combo3['total_common'] > 0:\n",
    "        h_mds_set = sig_sets3['H_F_MDS']\n",
    "        ta_set = sig_sets3['TA_F']\n",
    "        ts_set = sig_sets3['TS_F_MDS_1']\n",
    "        \n",
    "        venn3([h_mds_set, ta_set, ts_set],\n",
    "              ['H_MDS', 'TA_F', 'TS_MDS'], ax=ax3)\n",
    "        \n",
    "        total_common = combo3['total_common']\n",
    "        ax3.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax3.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('3. H_MDS vs TA_F vs TS_MDS\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # ROW 2\n",
    "    # 4. LE_MDS vs H_MDS vs NETRAD (Bottom-left)\n",
    "    ax4 = axes[1, 0]\n",
    "    combo4 = season_results['yearly']['combo4']\n",
    "    sig_sets4 = combo4['significance_sets']\n",
    "    \n",
    "    if combo4['total_common'] > 0:\n",
    "        le_mds_set = sig_sets4['LE_F_MDS']\n",
    "        h_mds_set = sig_sets4['H_F_MDS']\n",
    "        netrad_set = sig_sets4['NETRAD']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, netrad_set],\n",
    "              ['LE_MDS', 'H_MDS', 'NETRAD'], ax=ax4)\n",
    "        \n",
    "        total_common = combo4['total_common']\n",
    "        ax4.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax4.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('4. LE_MDS vs H_MDS vs NETRAD\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. H_MDS vs G_MDS vs SWC_MDS (Bottom-middle)\n",
    "    ax5 = axes[1, 1]\n",
    "    combo5 = season_results['yearly']['combo5']\n",
    "    sig_sets5 = combo5['significance_sets']\n",
    "    \n",
    "    if combo5['total_common'] > 0:\n",
    "        h_mds_set = sig_sets5['H_F_MDS']\n",
    "        g_set = sig_sets5['G_F_MDS']\n",
    "        swc_set = sig_sets5['SWC_F_MDS_1']\n",
    "        \n",
    "        venn3([h_mds_set, g_set, swc_set],\n",
    "              ['H_MDS', 'G_MDS', 'SWC_MDS'], ax=ax5)\n",
    "        \n",
    "        total_common = combo5['total_common']\n",
    "        ax5.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax5.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax5.transAxes, fontsize=12)\n",
    "    ax5.set_title('5. H_MDS vs G_MDS vs SWC_MDS\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. LE_MDS vs H_MDS vs GPP (Bottom-right)\n",
    "    ax6 = axes[1, 2]\n",
    "    combo6 = season_results['yearly']['combo6']\n",
    "    sig_sets6 = combo6['significance_sets']\n",
    "    \n",
    "    if combo6['total_common'] > 0:\n",
    "        le_mds_set = sig_sets6['LE_F_MDS']\n",
    "        h_mds_set = sig_sets6['H_F_MDS']\n",
    "        gpp_set = sig_sets6['GPP_DT_VUT_MEAN']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, gpp_set],\n",
    "              ['LE_MDS', 'H_MDS', 'GPP'], ax=ax6)\n",
    "        \n",
    "        total_common = combo6['total_common']\n",
    "        ax6.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax6.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax6.transAxes, fontsize=12)\n",
    "    ax6.set_title('6. LE_MDS vs H_MDS vs GPP\\n(Yearly)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add overall title\n",
    "    plt.suptitle('Venn Diagrams - Yearly Season\\n(Only stations with data for all 3 parameters, p < 0.2)', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(os.path.join(output_directory, 'venn_diagrams_common_stations_yearly.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print summary for Yearly\n",
    "    print(\"\\nYearly Season - Stations with all parameters:\")\n",
    "    for combo_name, combo_data in season_results['yearly'].items():\n",
    "        print(f\"  {combo_name}: {combo_data['total_common']} stations\")\n",
    "    \n",
    "    # Create the same for JJA season\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    \n",
    "    # ROW 1 for JJA\n",
    "    # 1. LE_MDS, H_MDS, SWC\n",
    "    ax1 = axes[0, 0]\n",
    "    combo1 = season_results['JJA']['combo1']\n",
    "    sig_sets1 = combo1['significance_sets']\n",
    "    \n",
    "    if combo1['total_common'] > 0:\n",
    "        le_mds_set = sig_sets1['LE_F_MDS']\n",
    "        h_mds_set = sig_sets1['H_F_MDS']\n",
    "        swc_set = sig_sets1['SWC_F_MDS_1']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, swc_set],\n",
    "              ['LE_MDS', 'H_MDS', 'SWC'], ax=ax1)\n",
    "        \n",
    "        total_common = combo1['total_common']\n",
    "        ax1.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax1.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax1.transAxes, fontsize=12)\n",
    "    ax1.set_title('1. LE_MDS vs H_MDS vs SWC\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. LE_MDS vs TA_F vs VPD_F\n",
    "    ax2 = axes[0, 1]\n",
    "    combo2 = season_results['JJA']['combo2']\n",
    "    sig_sets2 = combo2['significance_sets']\n",
    "    \n",
    "    if combo2['total_common'] > 0:\n",
    "        le_mds_set = sig_sets2['LE_F_MDS']\n",
    "        ta_set = sig_sets2['TA_F']\n",
    "        vpd_set = sig_sets2['VPD_F']\n",
    "        \n",
    "        venn3([le_mds_set, ta_set, vpd_set],\n",
    "              ['LE_MDS', 'TA_F', 'VPD_F'], ax=ax2)\n",
    "        \n",
    "        total_common = combo2['total_common']\n",
    "        ax2.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax2.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax2.transAxes, fontsize=12)\n",
    "    ax2.set_title('2. LE_MDS vs TA_F vs VPD_F\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. H_MDS vs TA_F vs TS_MDS\n",
    "    ax3 = axes[0, 2]\n",
    "    combo3 = season_results['JJA']['combo3']\n",
    "    sig_sets3 = combo3['significance_sets']\n",
    "    \n",
    "    if combo3['total_common'] > 0:\n",
    "        h_mds_set = sig_sets3['H_F_MDS']\n",
    "        ta_set = sig_sets3['TA_F']\n",
    "        ts_set = sig_sets3['TS_F_MDS_1']\n",
    "        \n",
    "        venn3([h_mds_set, ta_set, ts_set],\n",
    "              ['H_MDS', 'TA_F', 'TS_MDS'], ax=ax3)\n",
    "        \n",
    "        total_common = combo3['total_common']\n",
    "        ax3.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax3.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('3. H_MDS vs TA_F vs TS_MDS\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # ROW 2 for JJA\n",
    "    # 4. LE_MDS vs H_MDS vs NETRAD\n",
    "    ax4 = axes[1, 0]\n",
    "    combo4 = season_results['JJA']['combo4']\n",
    "    sig_sets4 = combo4['significance_sets']\n",
    "    \n",
    "    if combo4['total_common'] > 0:\n",
    "        le_mds_set = sig_sets4['LE_F_MDS']\n",
    "        h_mds_set = sig_sets4['H_F_MDS']\n",
    "        netrad_set = sig_sets4['NETRAD']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, netrad_set],\n",
    "              ['LE_MDS', 'H_MDS', 'NETRAD'], ax=ax4)\n",
    "        \n",
    "        total_common = combo4['total_common']\n",
    "        ax4.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax4.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('4. LE_MDS vs H_MDS vs NETRAD\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. H_MDS vs G_MDS vs SWC_MDS\n",
    "    ax5 = axes[1, 1]\n",
    "    combo5 = season_results['JJA']['combo5']\n",
    "    sig_sets5 = combo5['significance_sets']\n",
    "    \n",
    "    if combo5['total_common'] > 0:\n",
    "        h_mds_set = sig_sets5['H_F_MDS']\n",
    "        g_set = sig_sets5['G_F_MDS']\n",
    "        swc_set = sig_sets5['SWC_F_MDS_1']\n",
    "        \n",
    "        venn3([h_mds_set, g_set, swc_set],\n",
    "              ['H_MDS', 'G_MDS', 'SWC_MDS'], ax=ax5)\n",
    "        \n",
    "        total_common = combo5['total_common']\n",
    "        ax5.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax5.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax5.transAxes, fontsize=12)\n",
    "    ax5.set_title('5. H_MDS vs G_MDS vs SWC_MDS\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. LE_MDS vs H_MDS vs GPP\n",
    "    ax6 = axes[1, 2]\n",
    "    combo6 = season_results['JJA']['combo6']\n",
    "    sig_sets6 = combo6['significance_sets']\n",
    "    \n",
    "    if combo6['total_common'] > 0:\n",
    "        le_mds_set = sig_sets6['LE_F_MDS']\n",
    "        h_mds_set = sig_sets6['H_F_MDS']\n",
    "        gpp_set = sig_sets6['GPP_DT_VUT_MEAN']\n",
    "        \n",
    "        venn3([le_mds_set, h_mds_set, gpp_set],\n",
    "              ['LE_MDS', 'H_MDS', 'GPP'], ax=ax6)\n",
    "        \n",
    "        total_common = combo6['total_common']\n",
    "        ax6.text(0.5, -0.1, f'Stations with all params: {total_common}', \n",
    "                transform=ax6.transAxes, ha='center', va='top', \n",
    "                fontsize=11, fontweight='bold', color='darkblue')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'No stations with all parameters', ha='center', va='center', \n",
    "                transform=ax6.transAxes, fontsize=12)\n",
    "    ax6.set_title('6. LE_MDS vs H_MDS vs GPP\\n(JJA Summer)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add overall title for JJA\n",
    "    plt.suptitle('Venn Diagrams - JJA Summer Season\\n(Only stations with data for all 3 parameters, p < 0.2)', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(os.path.join(output_directory, 'venn_diagrams_common_stations_jja.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print summary for JJA\n",
    "    print(\"\\nJJA Season - Stations with all parameters:\")\n",
    "    for combo_name, combo_data in season_results['JJA'].items():\n",
    "        print(f\"  {combo_name}: {combo_data['total_common']} stations\")\n",
    "    \n",
    "    # Save detailed results to CSV\n",
    "    detailed_results = []\n",
    "    for season_name, season_data in season_results.items():\n",
    "        for combo_name, combo_info in season_data.items():\n",
    "            common_stations = combo_info['common_stations']\n",
    "            sig_sets = combo_info['significance_sets']\n",
    "            \n",
    "            # Get parameter names for this combo\n",
    "            params = param_combinations[combo_name]\n",
    "            \n",
    "            for station in common_stations:\n",
    "                # Check significance for each parameter\n",
    "                sig_status = {}\n",
    "                for param in params:\n",
    "                    sig_status[param] = station in sig_sets[param]\n",
    "                \n",
    "                # Count significant parameters\n",
    "                sig_count = sum(sig_status.values())\n",
    "                \n",
    "                detailed_results.append({\n",
    "                    'Season': season_name,\n",
    "                    'Combination': combo_name,\n",
    "                    'Station': station,\n",
    "                    'Parameters': ', '.join(params),\n",
    "                    'Significant_Count': sig_count,\n",
    "                    'LE_F_MDS_sig': sig_status.get('LE_F_MDS', False),\n",
    "                    'H_F_MDS_sig': sig_status.get('H_F_MDS', False),\n",
    "                    'SWC_F_MDS_1_sig': sig_status.get('SWC_F_MDS_1', False),\n",
    "                    'TA_F_sig': sig_status.get('TA_F', False),\n",
    "                    'VPD_F_sig': sig_status.get('VPD_F', False),\n",
    "                    'TS_F_MDS_1_sig': sig_status.get('TS_F_MDS_1', False),\n",
    "                    'NETRAD_sig': sig_status.get('NETRAD', False),\n",
    "                    'G_F_MDS_sig': sig_status.get('G_F_MDS', False),\n",
    "                    'GPP_DT_VUT_MEAN_sig': sig_status.get('GPP_DT_VUT_MEAN', False)\n",
    "                })\n",
    "    \n",
    "    if detailed_results:\n",
    "        detailed_df = pd.DataFrame(detailed_results)\n",
    "        detailed_df.to_csv(os.path.join(output_directory, 'common_stations_significance_details.csv'), index=False)\n",
    "        print(\"\\nDetailed significance data saved to CSV file\")\n",
    "    \n",
    "    print(\"\\nVenn diagrams created for common stations only\")\n",
    "\n",
    "\n",
    "    # New combined 2x3 Venn diagrams (only common stations with data for all parameters)\n",
    "create_combined_venn_diagrams_2x3_common_stations_only()\n",
    "\n",
    "# Replace the call to create_venn_diagrams_separate_seasons() with:\n",
    "print(\"Creating all Venn diagram variations...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
